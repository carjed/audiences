---
params: 
  title: ""
  datadir: ""
title: "`r params$title`"
output: 
  html_document:
    theme: flatly
    highlight: zenburn
    toc: false
    # code_folding: "hide"
    # includes:
      # before_body: header.html
      # after_body: themes/mondrian/layouts/partials/footer.html
    # toc_float: true
---

<style type="text/css">
div.main-container {
  max-width: 1536px;
  margin-left: auto;
  margin-right: auto;
}

</style>

<!-- h1, .h1, { -->
<!--     margin-top: 84px; -->
<!-- } -->

```{r setup, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
library(formattable)
library(plotly)
library(ggridges)
library(rcrossref)
library(ggbeeswarm)
library(shiny)

# base_url <- "http://192.168.2.22:1315"
base_url <- "https://carjed.github.io/audiences"

datadir <- "/mnt/norbert/home/jedidiah/projects/audiences"

summary_files <- file.info(
         list.files(path=paste0(datadir, "/article_data"), 
                    pattern="summary_data_",
                    full.names = TRUE))
summary_files <- rownames_to_column(summary_files) %>%
  arrange(mtime)

files <- summary_files$rowname

summary_data <- lapply(files, readRDS)

title <- unlist(lapply(summary_data, function(x) x$title))
doi <- unlist(lapply(summary_data, function(x) x$doi))
categories <- unlist(lapply(summary_data, function(x) x$categories))
id_score <- unlist(lapply(summary_data, function(x) x$id_score))

topics <- lapply(summary_data, function(x) x$topic)
names(topics) <- title

topics_df <- bind_rows(topics, .id = "title")
# pct_acad_am <- unlist(lapply(summary_data, function(x) (sum(as.numeric(x$am_cohorts))
# -as.numeric(x$am_cohorts$cohorts.pub))/sum(as.numeric(x$am_cohorts))
# ))

pct_acad_am <- unlist(lapply(summary_data, function(x) (as.numeric(x$am_cohorts$cohorts.sci)/sum(as.numeric(x$am_cohorts))
)))

get_acad_pct <- function(x){
  topics <- x$topics
  
  acad_topics <- topics %>%
    dplyr::filter(grepl("phd|md|dr", top_10)) %>%
    dplyr::filter(grepl("university|institute|universidad|lab|college", top_10)) %>%
    dplyr::filter(grepl("student|estudiante|postdoc|professor|profesor", top_10))
    
  pct_acad <- sum(acad_topics$n)/sum(topics$n)

}

pct_acad_aud <- unlist(lapply(summary_data, get_acad_pct))
n_users <- unlist(lapply(summary_data, function(x) nrow(x$homophily)))
wn_means_02 <- unlist(lapply(summary_data, function(x) sum(x$homophily$wn_mean>0.02)/nrow(x$homophily)))
wn_means_05 <- unlist(lapply(summary_data, function(x) sum(x$homophily$wn_mean>0.05)/nrow(x$homophily)))
wn_means_10 <- unlist(lapply(summary_data, function(x) sum(x$homophily$wn_mean>0.10)/nrow(x$homophily)))
wn_means_20 <- unlist(lapply(summary_data, function(x) sum(x$homophily$wn_mean>0.20)/nrow(x$homophily)))

summary_data_df <- data.frame(title, doi, categories_trim=categories, id_score, pct_acad_am, pct_acad_aud, wn_means_02, wn_means_05, wn_means_10, wn_means_20, n_users)

sddf2 <- left_join(topics_df, summary_data_df, by="title")

category_counts <- summary_data_df %>% group_by(categories_trim) %>% summarise(tot_tweets=sum(n_users), n_papers=n())

nat_counts <- sddf2 %>%
  dplyr::filter(grepl("#resist|#maga", top_10)) %>% 
  dplyr::mutate(pol=ifelse(grepl("#maga", top_10), "cons", "lib")) %>%
  group_by(categories_trim, pol) %>% 
  summarise(tot=sum(n)) %>% 
  ungroup() %>% 
  base::merge(category_counts, by="categories_trim") %>% mutate(prop=tot/tot_tweets) %>%
  dplyr::filter(n_papers>=10) %>%
  group_by(categories_trim) %>%
  dplyr::select(pol, prop) %>%
  spread(pol, prop) %>%
  mutate(ratio=log(cons/lib)) %>%
  arrange(desc(ratio))

sddf2 %>% dplyr::filter(grepl("socialist", top_10)) %>% summarise(tot=sum(n))
sddf2 %>% dplyr::filter(grepl("nationalist", top_10) & grepl("white", top_10)) %>% summarise(tot=sum(n))

n_acad_higher <- summary_data_df %>% dplyr::filter(pct_acad_aud>pct_acad_am) %>% nrow()
pct_acad_higher <- n_acad_higher/nrow(summary_data_df)

n_aud_50 <- summary_data_df %>% dplyr::filter(pct_acad_aud<0.5) %>% nrow()
n_am_50 <- summary_data_df %>% dplyr::filter(pct_acad_am<0.5) %>% nrow()

tot_bios <- sum(unlist(lapply(summary_data, function(x){
  tmp_dat <- x$homophily %>%
    mutate(followers_count=ifelse(followers_count>10000, 10000, followers_count)) %>%
    group_by(account) %>%
    summarise(followers_count=max(followers_count))
  
  sum(tmp_dat$followers_count, na.rm=T)
})))
```

<!-- # {.tabset .tabset-fade .tabset-pills} -->
# {.tabset .tabset-fade}

## Overview

<div class = "row">
<div class = "col-md-4">

**Audiences** analyzes the various communities and networks that are discussing scientific papers on Twitter. Our goal is to help authors better understand who is engaging with their work.

Click on the tabs above to view various summaries of the papers analyzed.

-------

- Number of papers indexed: **`r nrow(summary_data_df)`**

- Total events (tweets and retweets) analyzed: **`r format(sum(unlist(lapply(summary_data, function(x) nrow(x$homophily)))), big.mark=",")`**

- Total follower bios included in analysis: **`r format(tot_bios, big.mark=",")`** (includes overlap)

### Citation

These analyses are described in detail in the following paper:

> Carlson J, Harris K. {Title}. *Journal.* 2019. [`doi:10.1186/s12864-018-5264-y`](http://dx.doi.org/10.1186/s12864-018-5264-y)

</div>

<div class = "col-md-8">

Click a journal or category to view a catalog of individual reports for the top articles.

```{r data_summary, results="asis", echo=FALSE,  message=FALSE, error=FALSE, warning=FALSE}

categories_trim <- c("animal-behavior-and-cognition", 
                     "biochemistry", "bioengineering", "bioinformatics",
                     "biophysics", "cancer-biology", "cell-biology", "clinical-trials",
                     "developmental-biology", "ecology",
                     "epidemiology", "evolutionary-biology", 
                     "genetics", "genomics", "immunology", "microbiology", 
                     "molecular-biology", "neuroscience", "paleontology",
                     "pathology", "pharmacology-and-toxicology", "physiology", "plant-biology",
                     "scientific-communication-and-education",
                     "synthetic-biology", "systems-biology", "zoology")

# biorxiv category colors from 
# https://github.com/blekhmanlab/rxivist_web/blob/master/static/categories.css
cat_pal <- c("#EC7063", "#AF7AC5", "#A569BD", "#5499C7", "#5DADE2", "#48C9B0", "#45B39D", "#52BE80", "#58D68D", "#F4D03F", "#F5B041", "#EB984E", "#DC7633", "#F9E79F", "#AAB7B8", "#99A3A4", "#F1C40F", "#52BE80", "#C0392B", "#E74C3C", "#9B59B6", "#8E44AD", "#2980B9", "#3498DB", "#1ABC9C", "#16A085", "#27AE60")

cat_df1 <- data.frame(categories_trim, cat_pal) %>%
  mutate(categories_html = cell_spec(categories_trim, "html", 
                                     color = "black",
                                     bold = TRUE,
                                     background = cat_pal,
                                     link = paste0(base_url, "/tags/", categories_trim)))

# categories_trim <- 
  # mutate(categories_trim2=text_spec(categories_trim, paste0(base_url, "/tags/", categories_trim)))

# cat_df <- data.frame(matrix(cat_df1$categories_html, nrow=5, ncol=6)) #%>%


# for(url in urls){
#   cat(url)
# }
# 
# knitr::kable(cat_df, format="html", escape=F, align="c", col.names=NULL) %>%
#   kable_styling("striped", position="left", full_width = F)


# cat_df_count <- data.frame(categories_trim=categories) %>% 
cat_df_count <- summary_data_df %>%
  mutate(Journal = ifelse(grepl("10.1101", doi), "biorxiv", "NPG")) %>%
  group_by(categories_trim, Journal) %>% 
  summarise(npapers=n(),
            id_score=median(id_score),
            wn_means_02=mean(wn_means_02),
            wn_means_05=mean(wn_means_05),
            wn_means_10=mean(wn_means_10),
            wn_means_20=mean(wn_means_20)) %>%
  ungroup() %>%
  full_join(cat_df1, by="categories_trim") %>%
  arrange(categories_trim) %>%
  mutate(npapers=ifelse(is.na(npapers), 0, npapers)) %>%
  mutate(npapers=color_bar("lightgreen")(npapers)) %>%
  # mutate(id_score=color_tile("white", "orange")(round(id_score, 2))) %>%
  mutate(id_score = round(id_score, 2)) %>%
  mutate(id_score = cell_spec(
    id_score, color = "white", bold = T, align="c",
    background = spec_color(id_score, end = 1, option = "D", direction = -1))) %>%
  # mutate(Journal="biorxiv") %>%
  mutate(Journal = cell_spec(Journal, "html", 
                                   color = "white",
                                   bold = TRUE,
                                   background = "black",
                                   link = paste0(base_url, "/tags/", Journal))) %>%
  mutate(`Median \n Interdisciplinary Score`=id_score,
         `h=2%`=round(wn_means_02, 2),
         `h=5%`=round(wn_means_05, 2),
         `h=10%`=round(wn_means_10, 2),
         `h=20%`=round(wn_means_20, 2)) %>%
  mutate_at(vars(matches("h=")), function(x){
   cell_spec(x,
             "html",
             bold=TRUE,
             color = ifelse(is.na(x), "black", ifelse(x > 0, "red", "black")))
  }) %>%
  #  mutate_if(is.numeric, function(x) {
  #   cell_spec(x, bold = T, 
  #             color = spec_color(x, end = 0.9),
  #             font_size = spec_font_size(x))
  # }) %>%
  dplyr::select(Journal,
                Category=categories_html, 
                `Papers Analyzed`=npapers, 
                `Median \n Interdisciplinary Score`,
                `h=2%`,
                `h=5%`,
                `h=10%`,
                `h=20%`)

knitr::kable(cat_df_count, format="html", escape=F, align="l") %>%
  kable_styling("striped", full_width = F, position = "float_right") %>%
  add_header_above(c(" " = 4, "Average fraction of users with > h% \n white nationalist follower homophily" = 4)) %>%
  scroll_box(height = "576px")

```

</div>
</div>

## Academic demographics

<div class = "row">
<div class = "col-md-4">

Of the **`r nrow(summary_data_df)`** papers analyzed, our method estimates a higher fraction of the audiences are scientists than the Altmetric demographics for **`r n_acad_higher`** **(`r paste0(round((n_acad_higher/nrow(summary_data_df))*100), "%")`)** of these. 

According to the Altmetric demographics, **`r n_am_50`** of these papers **(`r paste0(round((n_am_50/nrow(summary_data_df))*100), "%")`)** are tweeted primarily by non-scientist audiences; our method estimates only **`r n_aud_50`** papers **(`r paste0(round((n_aud_50/nrow(summary_data_df))*100), "%")`)** are primarily tweeted by non-scientist audiences.

These audience demographic comparisons are summarized in the plot to the right. Points are colored according to their bioRxiv category, and the size is relative to the number of tweets/retweets referencing the paper. Click on a point to open the individual report.
</div>

<div class = "col-md-8">

```{r plot_acad_pct, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.height=6, fig.width=12}
# summary_data_doi <- try(cr_works(doi=summary_data_df$doi)$data)
# summary_data_doi <- tibble()
# for(doi in summary_data_df$doi){
#   # sdf_tmp <- summary_data_df %>% dplyr::filter(doi==doi)
#   summary_data_tmp <- cr_works(doi=doi)$data
#   summary_data_doi <- bind_rows(summary_data_doi, summary_data_tmp)
# }

# while(inherits(summary_data_doi, "try-error")){
#   summary_data_doi <- try(cr_works(doi=summary_data_df$doi)$data)
# }

acad_pct_dat <- summary_data_df %>%
  full_join(cat_df1, by="categories_trim") %>%
# plotdat <- left_join(summary_data_df, summary_data_doi) %>%
  rowwise() %>%
  mutate(urls=paste0(base_url, "/reports/", doi)) %>%
  dplyr::rename("category"="categories_trim")

plot_embedding <- function(plotdat){
  
  sci_cor <- cor(plotdat$pct_acad_am, plotdat$pct_acad_aud, use="complete.obs")

  p <- plotdat %>%
    ggplot(aes(x=pct_acad_am, y=pct_acad_aud, label=title))+
    geom_smooth(method="lm", se=FALSE)+
    geom_point(aes(size=n_users, colour=category), alpha=0.5)+
    scale_x_continuous(limits=c(0,0.8))+
    scale_y_continuous(limits=c(0,1))+
    # geom_smooth(method="lm")+
    scale_colour_manual(values=cat_pal)+
    geom_abline(intercept = 0, slope = 1, linetype="dashed")+
    # annotate("text", x = 0.8, y = 0.1, label = paste0("r=", round(sci_cor, 2)))+
    xlab("Fraction of audience that are scientists (Altmetric estimate)")+
    ylab("Fraction of audience that are scientists (Our estimate)")+
    theme_classic()+
    theme(legend.title = element_blank())
  
  ply <- ggplotly(p)
  
  # Clickable points link to profile URL using onRender: https://stackoverflow.com/questions/51681079
  # if(length(ply$x$data==12)){
    # for(i in 1:12){
  for(i in 1:length(ply$x$data)){
    query_category <- unique(ply$x$data[[i]]$name)
    
    ply$x$data[[i]]$customdata <- plotdat[plotdat$category==query_category,]$urls
  }
    
  # }
    #pp  <- add_markers(pp, customdata = ~url)
  plyout <- onRender(ply, "
                     function(el, x) {
                     el.on('plotly_click', function(d) {
                     var url = d.points[0].customdata;
                     //url
                     window.open(url);
                     });
                     }
                     ")

  plyout
}

plot_embedding(acad_pct_dat)

```




</div>

```{r ttests, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
ddf2 <- acad_pct_dat %>%
  dplyr::filter(grepl("10.1101", doi)) %>%
  group_by(category) %>%
  mutate(n=n()) %>%
  dplyr::filter(n>=20)
  # dplyr::filter(category %in% c("genomics", "neuroscience", "genetics", "evolutionary-biology", "bioinformatics"))

t1 <- pairwise.t.test(ddf2$pct_acad_am, ddf2$category, p.adj="fdr")

t2 <- pairwise.t.test(ddf2$pct_acad_aud, ddf2$category, p.adj="fdr")

knitr::kable(t1$p.value, format="html", escape=F, align="l", caption = "t-tests for differences in academic audience fraction based on Altmetric estimates (FDR-adjusted p-values)") %>%
  kable_styling("striped", full_width = F, position = "float_left")

knitr::kable(t2$p.value, format="html", escape=F, align="l", caption = "t-tests for differences in academic audience fraction based on our estimates (FDR-adjusted p-values)") %>%
  kable_styling("striped", full_width = F, position = "float_right")


```

</div>


## Interdisciplinary scores

<div class = "row">
<div class = "col-md-4">

For each paper, we calculated the cosine similarity between each of the academic audience topics and the most frequently-used words in the Wikipedia article corresponding to the research category under which the paper was submitted. We then calculated an interdisciplinary score as a weighted average of these cosine similarity scores, where the weights are the fraction of the academic audience associated with that topic: 

$ID_{score} = 1- \sum_{d \in D} w_d \times cos(\vec{d}, \vec{d}_{home})$

We then normalized these scores to range from 0 to 1, thus, papers with $ID_{score} \simeq 1$ have the most interdisciplinary academic audiences, and papers with $ID_{score} \simeq 0$ have the most domain-specific academic audiences.

</div>

<div class = "col-md-8">

```{r beeswarm, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.height=6, fig.width=12}
plotdat <- summary_data_df %>%
  full_join(cat_df1, by="categories_trim") %>%
# plotdat <- left_join(summary_data_df, summary_data_doi) %>%
  rowwise() %>%
  mutate(urls=paste0(base_url, "/reports/", doi)) %>%
  dplyr::rename("category"="categories_trim")

plot_embedding <- function(plotdat){
  
  p <- plotdat %>%
    ungroup() %>%
    mutate(id_score=scales::rescale(id_score,to=c(0, 1))) %>%
    ggplot(aes(x=category, y=id_score, label=title, colour=category))+
    geom_boxplot(outlier.shape=NA, outlier.colour="white", fill=NA)+
    geom_quasirandom(varwidth = TRUE, alpha=0.5)+
    # geom_smooth(method="lm", se=FALSE)+
    # geom_point(aes(size=n_users, colour=category), alpha=0.5)+
    # scale_x_continuous(limits=c(0,1))+
    # scale_y_continuous(limits=c(0,1))+
    # # geom_smooth(method="lm")+
    scale_colour_manual(values=cat_pal)+
    # geom_abline(intercept = 0, slope = 1, linetype="dashed")+
    # xlab("Fraction of audience that are scientists (Altmetric estimate)")+
    ylab("Interdisciplinary score")+
    theme_classic()+
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank(),
          legend.title=element_blank(),
          axis.title.x=element_blank())
  
  ply <- ggplotly(p) %>%
    plotly::style(hoverinfo = "none", traces = 1:26)
  
  # Clickable points link to profile URL using onRender: https://stackoverflow.com/questions/51681079
  # if(length(ply$x$data==12)){
    # for(i in 1:12){
  for(i in 1:length(ply$x$data)){
    query_category <- unique(ply$x$data[[i]]$name)
    
    ply$x$data[[i]]$customdata <- plotdat[plotdat$category==query_category,]$urls
  }
    
  # }
    #pp  <- add_markers(pp, customdata = ~url)
  plyout <- onRender(ply, "
                     function(el, x) {
                     el.on('plotly_click', function(d) {
                     var url = d.points[0].customdata;
                     //url
                     window.open(url);
                     });
                     }
                     ")

  plyout
}

plot_embedding(plotdat)
```

</div>
</div>

## Lay audience network homophily

<!-- {.tabset .tabset-fade .tabset-pills} -->

<!-- <div class = "row"> -->
<!-- <div class = "col-md-4"> -->

Many papers were found to have audience topics aligned with white nationalist rhetoric, reinforcing the qualitative observations made by [scientific organizations](), [science journalists](), and [scientists themselves](). To systematically quantify this trend, for each paper, we calculated the degree of network homophily (i.e., % overlap in followers) between each user and a curated set of prominent white nationalist accounts on Twitter. These plots show the distribution of white nationalist network homophily fraction ($h$) for the analyzed papers at four different thresholds ($h=2\%$, $h=5\%$, $h=10\%$, and $h=20\%$).

<!-- </div> -->

<!-- <div class = "col-md-8"> -->

```{r get_wn_dat, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
wn_dat <- summary_data_df %>%
  full_join(cat_df1, by="categories_trim") %>%
  gather(wn_means, h, wn_means_02:wn_means_20) %>%
  mutate(wn_means=recode(wn_means, 
                         wn_means_02="h=2%", 
                         wn_means_05="h=5%", 
                         wn_means_10="h=10%", 
                         wn_means_20="h=20%")) %>%
  mutate(wn_means=factor(wn_means)) %>%
  mutate(wn_means=factor(wn_means, levels=c("h=2%", "h=5%", "h=10%", "h=20%"))) %>%
  mutate(categories_trim=factor(categories_trim)) 

wn_plotfun <- function(x){
  p <- ggplot(x, aes(y=h, x=categories_trim, colour=categories_trim, label=title))+
  geom_boxplot(outlier.shape=NA, outlier.colour="white", fill=NA)+
  geom_quasirandom(varwidth = TRUE,  groupOnX=TRUE, alpha=0.6)+
  # scale_fill_manual(values=cat_pal)+
  scale_colour_manual(values=cat_pal)+
  # scale_y_continuous(breaks=seq(0, 0.6, 0.05), limits=c(-0.1,0.6))+
  # facet_wrap(~wn_means, ncol=1, strip.position="right")+
  ylab("Fraction of users with >h% \n white nationalist follower homophily \n \n")+
  theme_classic()+
  theme(#axis.text.x=element_text(angle=-45, hjust=1, size=10),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.title=element_blank(),
        # strip.background = element_blank(),
        axis.title.x=element_blank())
  
  ply <- ggplotly(p) %>%
    plotly::style(hoverinfo = "none", traces = 1:26)

  for(i in 1:length(ply$x$data)){
    query_category <- unique(ply$x$data[[i]]$name)
    
    ply$x$data[[i]]$customdata <- plotdat[plotdat$category==query_category,]$urls
  }
    
  # }
    #pp  <- add_markers(pp, customdata = ~url)
  plyout <- onRender(ply, "
                     function(el, x) {
                     el.on('plotly_click', function(d) {
                     var url = d.points[0].customdata;
                     //url
                     window.open(url);
                     });
                     }
                     ")

  plyout
  
  # test adding dropdown
  # p2$x$transforms <- list(
  #   list(
  #     type = 'filter',
  #     target = 'y',
  #     operation = '>',
  #     value = mean(mtcars$qsec)
  #   )
  # )
  
  
}

```

```{r eval=FALSE, echo=FALSE}
library(bsselectR)

wn2 <- wn_dat %>%
  dplyr::filter(wn_means=="h=2%") %>%
  wn_plotfun()

wn2_path <- paste0(params$datadir, "/static/wn2.html")

if(!file.exists(wn2_path)){
  htmlwidgets::saveWidget(as.widget(wn2), wn2_path)
}

wn5 <- wn_dat %>%
  dplyr::filter(wn_means=="h=5%") %>%
  wn_plotfun()

wn5_path <- paste0(params$datadir, "/static/wn5.html")

if(!file.exists(wn5_path)){
  htmlwidgets::saveWidget(as.widget(wn5), wn5_path)
}

plots <- gsub(paste0(params$datadir, "/static/"), "", c(wn2_path, wn5_path))

bsselect(plots, type = "iframe")

```

### {.tabset .tabset-dropdown}

#### h=2%

```{r plot_h2, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.height=4, fig.width=16}
wn_dat %>%
  dplyr::filter(wn_means=="h=2%") %>%
  wn_plotfun()

```

#### h=5%

```{r plot_h5, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.height=4, fig.width=16}
wn_dat %>%
  dplyr::filter(wn_means=="h=5%") %>%
  wn_plotfun()

```

#### h=10%

```{r plot_h10, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.height=4, fig.width=16}
wn_dat %>%
  dplyr::filter(wn_means=="h=10%") %>%
  wn_plotfun()

```

#### h=20%

```{r plot_h20, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, fig.height=4, fig.width=16}
wn_dat %>%
  dplyr::filter(wn_means=="h=20%") %>%
  wn_plotfun()

```

<!-- </div> -->
<!-- </div> -->

## About

```{r child = 'content/about.md'}
```
