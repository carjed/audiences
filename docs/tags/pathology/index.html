<!DOCTYPE html>
<html><head>
  
  <title>Pathology | audiences</title>
  
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/bootstrap.min.css'>
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/mondrian.css'>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.52" />
  

<style>

  #grid .list-item.page:hover {
    background: white;
  }
  main.single.page h1 {
    border-color: white;
  }

  #grid .list-item.reports:hover {
    background: gold;
  }
  main.single.reports h1 {
    border-color: gold;
  }

  #grid .list-item.summary:hover {
    background: limegreen;
  }
  main.single.summary h1 {
    border-color: limegreen;
  }

</style>
  









<script src="https://carjed.github.io/audiences/js/bundle.min.f25ff27688046eb318bdc22977150cde493b69297eb61c33d467745adf840d358a2427ed01d7dc1e0bd54c4d5831f1ed5e9bc1e1f7187533a24e36d63659607f.js" integrity="sha512-8l/ydogEbrMYvcIpdxUM3kk7aSl&#43;thwz1Gd0Wt&#43;EDTWKJCftAdfcHgvVTE1YMfHtXpvB4fcYdTOiTjbWNllgfw=="></script>

  <style></style>
  
  
</head>
<body>
  <div class="container-fluid h-100 d-flex flex-column">
<header class="row flex-shrink-0 justify-content-center justify-content-md-start">
  <ul class="nav px-2">
    <li class="p-2">
      <a class="text-muted text-decoration-none" href="../../">audiences</a>
    </li>
    
      <li class="p-2">
        <a class="text-light" href="reports" title="">reports</a>
      </li>
    
      <li class="p-2">
        <a class="text-light" href="search" title="">search</a>
      </li>
    
  </nav>
</header>

<main id="grid" class="row list flex-wrap h-99 text-center">
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/complete_genome_characterisation_of_a_novel_coronavirus_associated_with_severe_human_respiratory_disease_in_wuhan_china_74813373/">
          <h4 class="font-weight-bold">Complete genome characterisation of a novel coronavirus associated with severe human respiratory disease in Wuhan, China, bioRxiv, 2020-01-26</h4>
          <p>Emerging and re-emerging infectious diseases, such as SARS, MERS, Zika and highly pathogenic influenza present a major threat to public health1–3. Despite intense research effort, how, when and where novel diseases appear are still the source of considerable uncertainly. A severe respiratory disease was recently reported in the city of Wuhan, Hubei province, China. At the time of writing, at least 62 suspected cases have been reported since the first patient was hospitalized on December 12nd 2019. Epidemiological investigation by the local Center for Disease Control and Prevention (CDC) suggested that the outbreak was associated with a sea food market in Wuhan. We studied seven patients who were workers at the market, and collected bronchoalveolar lavage fluid (BALF) from one patient who exhibited a severe respiratory syndrome including fever, dizziness and cough, and who was admitted to Wuhan Central Hospital on December 26th 2019. Next generation metagenomic RNA sequencing4 identified a novel RNA virus from the family Coronaviridae designed WH-Human-1 coronavirus (WHCV).Phylogenetic analysis of the complete viral genome (29,903 nucleotides) revealed that WHCV was most closely related (89.1% nucleotide similarity similarity) to a group of Severe Acute Respiratory Syndrome (SARS)-like coronaviruses (genus Betacoronavirus, subgenus Sarbecovirus) previously sampled from bats in China and that have a history of genomic recombination. This outbreak highlights the ongoing capacity of viral spill-over from animals to cause severe disease in humans.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/pathology">pathology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/2020">2020</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/interpretable_multimodal_deep_learning_for_real-time_pan-tissue_pan-disease_pathology_search_on_social_media_46797097/">
          <h4 class="font-weight-bold">Interpretable multimodal deep learning for real-time pan-tissue pan-disease pathology search on social media, bioRxiv, 2018-08-21</h4>
          <p>AbstractBackgroundPathologists are responsible for rapidly providing a diagnosis on critical health issues, from infection to malignancy. Challenging cases benefit from additional opinions of pathologist colleagues. In addition to on-site colleagues, there is an active worldwide community of pathologists on social media for complementary opinions. Such access to pathologists worldwide has the capacity to (i) improve diagnostic accuracy and (ii) generate broader consensus on next steps in patient care.Methods and findingsFrom Twitter we curate 13,626 images from 6,351 tweets from 25 pathologists from 13 countries. We supplement the Twitter data with 113,161 images from 1,074,484 PubMed articles. We develop machine learning and deep learning models to (i) accurately identify histopathology stains, (ii) discriminate between tissues, and (iii) differentiate disease states. For deep learning, we derive novel regularization and activation functions for set representations related to set cardinality and the Heaviside step function. Area Under Receiver Operating Characteristic is 0.805-0.996 for these tasks. We repurpose the disease classifier to search for similar disease states given an image and clinical covariates. We report precision@k=1 = 0.701±0.003 (chance 0.397±0.004, mean±stdev). The classifiers find texture and tissue are important clinico-visual features of disease. For search, deep features and cell nuclei features are less important.We implement a social media bot (@pathobot on Twitter) to use the trained classifiers to aid pathologists in obtaining real-time feedback on challenging cases. The bot activates when mentioned in a social media post containing pathology text and images. The bot generates quantitative predictions of disease state (normalartifact infectioninjurynontumor, pre-neoplasticbenignlow-grade-malignant-potential, or malignant) and provides a ranked list of similar cases across social media and PubMed.ConclusionsOur project has become a globally distributed expert system that facilitates pathological diagnosis and brings expertise to underserved regions or hospitals with less expertise in a particular disease. This is the first pan-tissue pan-disease (i.e. from infections to malignancy) method for prediction and search on social media, and the first pathology study prospectively tested in public on social media. We expect our project to cultivate a more connected world of physicians and improve patient care worldwide.Author summaryWhy was this study done?&lt;jatslist list-type=bullet&gt;&lt;jatslist-item&gt;No publicly available pan-tissue pan-disease dataset exists for computational pathology. This limits the general application of machine learning in histopathology.&lt;jatslist-item&gt;&lt;jatslist-item&gt;Pathologists use social media to obtain both (i) opinions for challenging patient cases and (ii) continuing education. Connecting pathologists and linking to similar cases leads to more informative exchanges than computational predictions – e.g. to diagnose best, pathologists may discuss patient history and next tests to order. Additionally, pathologists seek the most interesting rare cases and new articles.&lt;jatslist-item&gt;What did the researchers do and find?&lt;jatslist list-type=bullet&gt;&lt;jatslist-item&gt;We generated a pan-tissue, pan-disease dataset comprising 10,000&#43; images from social media and 100,000&#43; images from PubMed. Classifiers applied to social media data suggest texture and tissue are important clinico-visual features of disease. Learning from both clinical covariates (e.g. tissue type or marker mentions) and visual features (e.g. local binary patterns or deep learning image features), these classifiers are multimodal.&lt;jatslist-item&gt;&lt;jatslist-item&gt;These data and classifiers power the first social media bot for pathology. It responds to pathologists in real time, searches for similar cases, and encourages collaboration.&lt;jatslist-item&gt;What do these findings mean?&lt;jatslist list-type=bullet&gt;&lt;jatslist-item&gt;This diverse dataset will be a critical test for machine learning in computational pathology, e.g. search for cures of rare diseases.&lt;jatslist-item&gt;&lt;jatslist-item&gt;Interpretable real-time classifiers can be successfully applied to images on social media and PubMed to find similar diseases and generate disease predictions. Going forward, similar methods may elucidate important clinico-visual features of specific diseases.&lt;jatslist-item&gt;</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/pathology">pathology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/adversarial_childhood_events_are_associated_with_sudden_infant_death_syndrome_sids_an_ecological_study_43429589/">
          <h4 class="font-weight-bold">Adversarial childhood events are associated with Sudden Infant Death Syndrome (SIDS) an ecological study, bioRxiv, 2018-06-07</h4>
          <p>AbstractSudden Infant Death Syndrome (SIDS) is the most common cause of postneonatal infant death. The allostatic load hypothesis posits that SIDS is the result of perinatal cumulative painful, stressful, or traumatic exposures that tax neonatal regulatory systems. To test it, we explored the relationships between SIDS and two common stressors, male neonatal circumcision (MNC) and prematurity, using latitudinal data from 15 countries and over 40 US states during the years 1999-2016. We used linear regression analyses and likelihood ratio tests to calculate the association between SIDS and the stressors. SIDS prevalence was significantly and positively correlated with MNC and prematurity rates. MNC explained 14.2% of the variability of SIDS’s male bias in the US, reminiscent of the Jewish myth of Lilith, the killer of infant males. Combined, the stressors increased the likelihood of SIDS. Ecological analyses are useful to generate hypotheses but cannot provide strong evidence of causality. Biological plausibility is provided by a growing body of experimental and clinical evidence linking adversary preterm and early-life events with SIDS. Together with historical evidence, our findings emphasize the necessity of cohort studies that consider these environmental stressors with the aim of improving the identification of at-risk infants and reducing infant mortality.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/pathology">pathology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/deep_convolutional_neural_networks_for_breast_cancer_histology_image_analysis_32702437/">
          <h4 class="font-weight-bold">Deep Convolutional Neural Networks for Breast Cancer Histology Image Analysis, bioRxiv, 2018-02-08</h4>
          <p>AbstractBreast cancer is one of the main causes of cancer death worldwide. Early diagnostics significantly increases the chances of correct treatment and survival, but this process is tedious and often leads to a disagreement between pathologists. Computer-aided diagnosis systems showed potential for improving the diagnostic accuracy. In this work, we develop the computational approach based on deep convolution neural networks for breast cancer histology image classification. Hematoxylin and eosin stained breast histology microscopy image dataset is provided as a part of the ICIAR 2018 Grand Challenge on Breast Cancer Histology Images. Our approach utilizes several deep neural network architectures and gradient boosted trees classifier. For 4-class classification task, we report 87.2% accuracy. For 2-class classification task to detect carcinomas we report 93.8% accuracy, AUC 97.3%, and sensitivityspecificity 96.588.0% at the high-sensitivity operating point. To our knowledge, this approach outperforms other common methods in automated histopathological image classification. The source code for our approach is made publicly available at &lt;jatsext-link xmlnsxlink=httpwww.w3.org1999xlink ext-link-type=uri xlinkhref=httpsgithub.comalexander-rakhlinICIAR2018&gt;httpsgithub.comalexander-rakhlinICIAR2018&lt;jatsext-link&gt;</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/pathology">pathology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/pediatric_bone_age_assessment_using_deep_convolutional_neural_networks_30444746/">
          <h4 class="font-weight-bold">Pediatric Bone Age Assessment Using Deep Convolutional Neural Networks, bioRxiv, 2017-12-15</h4>
          <p>AbstractSkeletal bone age assessment is a common clinical practice to diagnose endocrine and metabolic disorders in child development. In this paper, we describe a fully automated deep learning approach to the problem of bone age assessment using data from the 2017 Pediatric Bone Age Challenge organized by the Radiological Society of North America. The dataset for this competition consists of 12,600 radiological images. Each radiograph in this dataset is an image of a left hand labeled with bone age and sex of a patient. Our approach utilizes several deep neural network architectures trained end-to-end. We use images of whole hands as well as specific parts of a hand for both training and prediction. This approach allows us to measure the importance of specific hand bones for automated bone age analysis. We further evaluate the performance of the suggested method in the context of skeletal development stages. Our approach outperforms other common methods for bone age assessment.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/pathology">pathology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/200-500-users">200-500-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/2017">2017</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/he-stained_whole_slide_image_deep_learning_predicts_spop_mutation_state_in_prostate_cancer_9796478/">
          <h4 class="font-weight-bold">H&amp;E-stained Whole Slide Image Deep Learning Predicts SPOP Mutation State in Prostate Cancer, bioRxiv, 2016-07-18</h4>
          <p>A quantitative model to genetically interpret the histology in whole microscopy slide images is desirable to guide downstream immuno-histochemistry, genomics, and precision medicine. We constructed a statistical model that predicts whether or not SPOP is mutated in prostate cancer, given only the digital whole slide after standard hematoxylin and eosin [H&amp;amp;E] staining. Using a TCGA cohort of 177 prostate cancer patients where 20 had mutant SPOP, we trained multiple ensembles of residual networks, accurately distinguishing SPOP mutant from SPOP non-mutant patients (test AUROC=0.74, p=0.0007 Fisher’s Exact Test). We further validated our full metaensemble classifier on an independent test cohort from MSK-IMPACT of 152 patients where 19 had mutant SPOP. Mutants and non-mutants were accurately distinguished despite TCGA slides being frozen sections and MSK-IMPACT slides being formalin-fixed paraffin-embedded sections (AUROC=0.86, p=0.0038). Moreover, we scanned an additional 36 MSK-IMPACT patients having mutant SPOP, trained on this expanded MSK-IMPACT cohort (test AUROC=0.75, p=0.0002), tested on the TCGA cohort (AUROC=0.64, p=0.0306), and again accurately distinguished mutants from non-mutants using the same pipeline. Importantly, our method demonstrates tractable deep learning in this “small data” setting of 20-55 positive examples and quantifies each prediction’s uncertainty with confidence intervals. To our knowledge, this is the first statistical model to predict a genetic mutation in cancer directly from the patient’s digitized H&amp;amp;E-stained whole microscopy slide. Moreover, this is the first time quantitative features learned from patient genetics and histology have been used for content-based image retrieval, finding similar patients for a given patient where the histology appears to share the same genetic driver of disease i.e. SPOP mutation (p=0.0241 Kost’s Method), and finding similar patients for a given patient that does not have have that driver mutation (p=0.0170 Kost’s Method).Significance StatementThis is the first pipeline predicting gene mutation probability in cancer from digitized H&amp;amp;E-stained microscopy slides. To predict whether or not the speckle-type POZ protein [SPOP] gene is mutated in prostate cancer, the pipeline (i) identifies diagnostically salient slide regions, (ii) identifies the salient region having the dominant tumor, and (iii) trains ensembles of binary classifiers that together predict a confidence interval of mutation probability. Through deep learning on small datasets, this enables automated histologic diagnoses based on probabilities of underlying molecular aberrations and finds histologically similar patients by learned genetic-histologic relationships.Conception, Writing AJS, TJF. Algorithms, Learning, CBIR AJS. Analysis AJS, MAR, TJF. Supervision MAR, TJF.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/pathology">pathology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="../../tags/2016">2016</a>
          
        
      </div>
    </div>
  
</main>
<br>
<main>
  


</main>

&nbsp;
<hr />
<p style="text-align: center;">Created with the <a href="https://github.com/carjed/audiences">audiences framework </a> by <a href="https://github.com/carjed/">Jedidiah Carlson</a></p>
<p style="text-align: center;">Powered by <a href="https://gohugo.io/">Hugo </a></p>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<p style="text-align: center;">
    <a href="https://twitter.com/JedMSP?lang=en" class="fa fa-twitter"></a>
    <a href="https://github.com/carjed/" class="fa fa-github"></a>
</p>

&nbsp;

</div>
  
</body>
</html>
