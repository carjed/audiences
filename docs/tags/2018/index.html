<!DOCTYPE html>
<html><head>
  
  <title>2018 | audiences</title>
  
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/bootstrap.min.css'>
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/mondrian.css'>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.52" />
  

<style>

  #grid .list-item.page:hover {
    background: white;
  }
  main.single.page h1 {
    border-color: white;
  }

  #grid .list-item.reports:hover {
    background: gold;
  }
  main.single.reports h1 {
    border-color: gold;
  }

  #grid .list-item.summary:hover {
    background: limegreen;
  }
  main.single.summary h1 {
    border-color: limegreen;
  }

</style>
  









<script src="https://carjed.github.io/audiences/js/bundle.min.f25ff27688046eb318bdc22977150cde493b69297eb61c33d467745adf840d358a2427ed01d7dc1e0bd54c4d5831f1ed5e9bc1e1f7187533a24e36d63659607f.js" integrity="sha512-8l/ydogEbrMYvcIpdxUM3kk7aSl&#43;thwz1Gd0Wt&#43;EDTWKJCftAdfcHgvVTE1YMfHtXpvB4fcYdTOiTjbWNllgfw=="></script>

  <style></style>
  
  
</head>
<body>
  <div class="container-fluid h-100 d-flex flex-column">
<header class="row flex-shrink-0 justify-content-center justify-content-md-start">
  <ul class="nav px-2">
    <li class="p-2">
      <a class="text-muted text-decoration-none" href="/">audiences</a>
    </li>
    
      <li class="p-2">
        <a class="text-light" href="reports" title="">reports</a>
      </li>
    
      <li class="p-2">
        <a class="text-light" href="search" title="">search</a>
      </li>
    
  </nav>
</header>

<main id="grid" class="row list flex-wrap h-99 text-center">
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/flowers_respond_to_pollinator_sound_within_minutes_by_increasing_nectar_sugar_concentration_53245752/">
          <h4 class="font-weight-bold">Flowers respond to pollinator sound within minutes by increasing nectar sugar concentration, bioRxiv, 2018-12-29</h4>
          <p>Can plants hear? That is, can they sense airborne sounds and respond to them? Here we show that Oenothera drummondii flowers, exposed to the playback sound of a flying bee or to synthetic sound-signals at similar frequencies, produced sweeter nectar within 3 minutes, potentially increasing the chances of cross pollination. We found that the flowers vibrated mechanically in response to these sounds, suggesting a plausible mechanism where the flower serves as the plantâ€™s auditory sensory organ. Both the vibration and the nectar response were frequency-specific the flowers responded to pollinator sounds, but not to higher frequency sound. Our results document for the first time that plants can rapidly respond to pollinator sounds in an ecologically relevant way. Sensitivity of plants to pollinator sound can affect plant-pollinator interactions in a wide range of ways Plants could allocate their resources more adequately, focusing on the time of pollinator activity; pollinators would then be better rewarded per time unit; flower shape may be selected for its effect on hearing ability, and not only on signaling; and pollinators may evolve to make sounds that the flowers can hear. Finally, our results suggest that plants may be affected by other sounds as well, including antropogenic ones.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/ecology">ecology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/500&#43;-users">500&#43;-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/highly_multiplexed_in_situ_protein_imaging_with_signal_amplification_by_immuno-saber_53240706/">
          <h4 class="font-weight-bold">Highly multiplexed in situ protein imaging with signal amplification by Immuno-SABER, bioRxiv, 2018-12-29</h4>
          <p>AbstractProbing the molecular organization of tissues requires in situ analysis by microscopy. However current limitations in multiplexing, sensitivity, and throughput collectively constitute a major barrier for comprehensive single-cell profiling of proteins. Here, we report Immunostaining with Signal Amplification By Exchange Reaction (Immuno-SABER), a rapid, highly multiplexed signal amplification method that simultaneously tackles these key challenges. Immuno-SABER utilizes DNA-barcoded antibodies and provides a method for highly multiplexed signal amplification via modular orthogonal DNA concatemers generated by Primer Exchange Reaction. This approach offers the capability to preprogram and control the amplification level independently for multiple targets without in situ enzymatic reactions, and the intrinsic scalability to rapidly amplify and image a large number of protein targets. We validated our approach in diverse sample types including cultured cells, cryosections, FFPE sections, and whole mount tissues. We demonstrated independently tunable 5-180-fold amplification for multiple targets, covering the full signal range conventionally achieved by secondary antibodies to tyramide signal amplification, as well as simultaneous signal amplification for 10 different proteins using standard equipment and workflow. We further combined Immuno-SABER with Expansion Microscopy to enable rapid and highly multiplexed super-resolution tissue imaging. Overall, Immuno-SABER presents an effective and accessible platform for rapid, multiplexed imaging of proteins across scales with high sensitivity.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/cell-biology">cell-biology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/200-500-users">200-500-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/human_microbiome_aging_clocks_based_on_deep_learning_and_tandem_of_permutation_feature_importance_and_accumulated_local_effects_53245742/">
          <h4 class="font-weight-bold">Human microbiome aging clocks based on deep learning and tandem of permutation feature importance and accumulated local effects, bioRxiv, 2018-12-29</h4>
          <p>The human gut microbiome is a complex ecosystem that both affects and is affected by its host status. Previous analyses of gut microflora revealed associations between specific microbes and host health and disease status, genotype and diet. Here, we developed a method of predicting the biological age of the host based on the microbiological profiles of gut microbiota using a curated dataset of 1,165 healthy individuals (1,663 microbiome samples). Our predictive model, a human microbiome clock, has an architecture of a deep neural network and achieves the accuracy of 3.94 years mean absolute error in cross-validation. The performance of the deep microbiome clock was also evaluated on several additional populations. We further introduce a platform for biological interpretation of individual microbial features used in age models, which relies on permutation feature importance and accumulated local effects. This approach has allowed us to define two lists of 95 intestinal biomarkers of human aging. We further show that this list can be reduced to 39 taxa that convey the most information on their host&#39;s aging. Overall, we show that (a) microbiological profiles can be used to predict human age; and (b) microbial features selected by models are age-related.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/bioinformatics">bioinformatics</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/200-500-users">200-500-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/inception_in_visual_cortex_in_vivo-silico_loops_reveal_most_exciting_images_53244634/">
          <h4 class="font-weight-bold">Inception in visual cortex in vivo-silico loops reveal most exciting images, bioRxiv, 2018-12-29</h4>
          <p>Much of our knowledge about sensory processing in the brain is based on quasi-linear models and the stimuli that optimally drive them. However, sensory information processing is nonlinear, even in primary sensory areas, and optimizing sensory input is difficult due to the high-dimensional input space. We developed inception loops, a closed-loop experimental paradigm that combines in vivo recordings with in silico nonlinear response modeling to identify the Most Exciting Images (MEIs) for neurons in mouse V1. When presented back to the brain, MEIs indeed drove their target cells significantly better than the best stimuli identified by linear models. The MEIs exhibited complex spatial features that deviated from the textbook ideal of V1 as a bank of Gabor filters. Inception loops represent a widely applicable new approach to dissect the neural mechanisms of sensation.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/plants_emit_informative_airborne_sounds_under_stress_53244340/">
          <h4 class="font-weight-bold">Plants emit informative airborne sounds under stress, bioRxiv, 2018-12-29</h4>
          <p>Stressed plants show altered phenotypes, including changes in color, smell, and shape. Yet, the possibility that plants emit airborne sounds when stressed, similarly to many animals, has not been investigated. Here we show, to our knowledge for the first time, that stressed plants emit airborne sounds that can be recorded remotely, both in acoustic chambers and in greenhouses. We recorded ~65 dBSPL ultrasonic sounds 10 cm from tomato and tobacco plants, implying that these sounds could be detected by some organisms from up to several meters away. We developed machine learning models that were capable of distinguishing between plant sounds and general noises, and identifying the condition of the plants dry, cut, or intact, based solely on the emitted sounds. Our results suggest that animals, humans, and possibly even other plants, could use sounds emitted by a plant to gain information about the plant&#39;s condition. More investigation on plant bioacoustics in general and on sound emission in plants in particular may open new avenues for understanding plants and their interactions with the environment, and it may also have a significant impact on agriculture.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/plant-biology">plant-biology</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/500&#43;-users">500&#43;-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/neocortical_layer_4_in_adult_mouse_differs_in_major_cell_types_and_circuit_organization_between_primary_sensory_areas_53203823/">
          <h4 class="font-weight-bold">Neocortical layer 4 in adult mouse differs in major cell types and circuit organization between primary sensory areas, bioRxiv, 2018-12-28</h4>
          <p>AbstractLayer 4 (L4) of mammalian neocortex plays a crucial role in cortical information processing, yet a complete census of its cell types and connectivity remains elusive. Using whole-cell recordings with morphological recovery, we identified one major excitatory and seven inhibitory types of neurons in L4 of adult mouse visual cortex (V1). Nearly all excitatory neurons were pyramidal and all somatostatin-positive (SOM&#43;) non-fast-spiking neurons were Martinotti cells. In contrast, in somatosensory cortex (S1), excitatory neurons were mostly stellate and SOM&#43; neurons were non-Martinotti. These morphologically distinct SOM&#43; interneurons corresponded to different transcriptomic cell types and were differentially integrated into the local circuit with only S1 neurons receiving local excitatory input. We propose that cell-type specific circuit motifs, such as the Martinottipyramidal and non-Martinottistellate pairs, are optionally used across the cortex as building blocks to assemble cortical circuits.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2018">2018</a>
          
        
      </div>
    </div>
  
</main>
<br>
<main>
  


<nav aria-label="page navigation">
    <ul class="pagination">
        
        

        

        
             
            <li class="page-item active"><a href="/audiences/tags/2018/" class="page-link">1</a></li>
            
        
            
             
            <li class="page-item"><a href="/audiences/tags/2018/page/2/" class="page-link">2</a></li>
            
        
            
             
            <li class="page-item"><a href="/audiences/tags/2018/page/3/" class="page-link">3</a></li>
            
        
            
             
            <li class="page-item"><a href="/audiences/tags/2018/page/4/" class="page-link">4</a></li>
            
        
            
             
            <li class="page-item"><a href="/audiences/tags/2018/page/5/" class="page-link">5</a></li>
            
        
             
            
            <li class="page-item disabled"><a class="page-link">...</a></li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        

        
        <li class="page-item"><a href="/audiences/tags/2018/page/2/" rel="next" class="page-link">Next â€º</a></li>
        

        
        
        <li class="page-item"><a href="/audiences/tags/2018/page/84/" rel="last" class="page-link">Last Â»</a></li>
        
    </ul>
</nav>


</main>

&nbsp;
<hr />
<p style="text-align: center;">Created with the <a href="https://github.com/carjed/audiences">audiences framework </a> by <a href="https://github.com/carjed/">Jedidiah Carlson</a></p>
<p style="text-align: center;">Powered by <a href="https://gohugo.io/">Hugo </a></p>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<p style="text-align: center;">
    <a href="https://twitter.com/JedMSP?lang=en" class="fa fa-twitter"></a>
    <a href="https://github.com/carjed/" class="fa fa-github"></a>
</p>

&nbsp;

</div>
  
</body>
</html>
