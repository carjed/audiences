<!DOCTYPE html>
<html><head>
  
  <title>Neuroscience | audiences</title>
  
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/bootstrap.min.css'>
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/mondrian.css'>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.52" />
  

<style>

  #grid .list-item.page:hover {
    background: white;
  }
  main.single.page h1 {
    border-color: white;
  }

  #grid .list-item.reports:hover {
    background: gold;
  }
  main.single.reports h1 {
    border-color: gold;
  }

  #grid .list-item.summary:hover {
    background: limegreen;
  }
  main.single.summary h1 {
    border-color: limegreen;
  }

</style>
  









<script src="https://carjed.github.io/audiences/js/bundle.min.f25ff27688046eb318bdc22977150cde493b69297eb61c33d467745adf840d358a2427ed01d7dc1e0bd54c4d5831f1ed5e9bc1e1f7187533a24e36d63659607f.js" integrity="sha512-8l/ydogEbrMYvcIpdxUM3kk7aSl&#43;thwz1Gd0Wt&#43;EDTWKJCftAdfcHgvVTE1YMfHtXpvB4fcYdTOiTjbWNllgfw=="></script>

  <style></style>
  
  
</head>
<body>
  <div class="container-fluid h-100 d-flex flex-column">
<header class="row flex-shrink-0 justify-content-center justify-content-md-start">
  <ul class="nav px-2">
    <li class="p-2">
      <a class="text-muted text-decoration-none" href="https://carjed.github.io/audiences/">audiences</a>
    </li>
    
      <li class="p-2">
        <a class="text-light" href="https://carjed.github.io/audiences/reports" title="">reports</a>
      </li>
    
      <li class="p-2">
        <a class="text-light" href="https://carjed.github.io/audiences/search" title="">search</a>
      </li>
    
  </nav>
</header>

<main id="grid" class="row list flex-wrap h-99 text-center">
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/polygenic_architecture_of_human_neuroanatomical_diversity_57963714/">
          <h4 class="font-weight-bold">Polygenic architecture of human neuroanatomical diversity, bioRxiv, 2019-03-29</h4>
          <p>AbstractWe analysed the genomic architecture of neuroanatomical diversity using magnetic resonance imaging and SNP data from &amp;gt; 20,000 individuals. Our results replicate previous findings of a strong polygenic architecture of neuroanatomical diversity. SNPs captured from 40% to 54% of the variance in the volume of different brain regions. We observed a large correlation between chromosome length and the amount of phenotypic variance captured, r∼0.64 on average, suggesting that at a global scale causal variants are homogeneously distributed across the genome. At a more local scale, SNPs within genes (∼51%) captured ∼1.5-times more genetic variance than the rest; and SNPs with low minor allele frequency (MAF) captured significantly less variance than those with higher MAF the 40% of SNPs with MAF&amp;lt;5% captured less than one fourth of the genetic variance. We also observed extensive pleiotropy across regions, with an average genetic correlation of rG∼0.45. Across regions, genetic correlations were in general similar to phenotypic correlations. By contrast, genetic correlations were larger than phenotypic correlations for the leftright volumes of the same region, and indistinguishable from 1. Additionally, the differences in leftright volumes were not heritable, underlining the role of environmental causes in the variability of brain asymmetry. Our analysis code is available at &lt;jatsext-link xmlnsxlink=httpwww.w3.org1999xlink ext-link-type=uri xlinkhref=httpsgithub.comneuroanatomygenomic-architecture&gt;httpsgithub.comneuroanatomygenomic-architecture&lt;jatsext-link&gt;.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2019">2019</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/modulation_of_visual_cortex_by_hippocampal_signals_57643128/">
          <h4 class="font-weight-bold">Modulation of visual cortex by hippocampal signals, bioRxiv, 2019-03-25</h4>
          <p>Neurons in primary visual cortex (V1) are influenced by the animal’s position in the environment and encode positions that correlate with those encoded by hippocampus (CA1). Might V1’s encoding of spatial positions be inherited from hippocampal regions? If so, it should depend on non-visual factors that affect the encoding of position in hippocampus, such as the physical distance traveled and the phase of theta oscillations. We recorded V1 and CA1 neurons while mice ran through a virtual corridor and confirmed these predictions. Spatial representations in V1 and CA1 were correlated even in the absence of visual cues. Moreover, similar to CA1 place cells, the spatial responses of V1 neurons were influenced by the physical distance traveled and the phase of hippocampal theta oscillations. These results reveal a modulation of cortical sensory processing by non-sensory estimates of position that might originate in hippocampal regions.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2019">2019</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/an_image-computable_model_for_the_stimulus_selectivity_of_gamma_oscillations_57449687/">
          <h4 class="font-weight-bold">An image-computable model for the stimulus selectivity of gamma oscillations, bioRxiv, 2019-03-22</h4>
          <p>AbstractGamma oscillations in visual cortex have been hypothesized to be critical for perception, cognition, and information transfer. However, observations of these oscillations in visual cortex vary widely; some studies report little to no stimulus-induced narrowband gamma oscillations, others report oscillations for only some stimuli, and yet others report large oscillations for most stimuli. To reconcile these findings and better understand this signal, we developed a model that predicts gamma responses for arbitrary images and validated this model on electrocorticography (ECoG) data from human visual cortex. The model computes variance across the outputs of spatially pooled orientation channels, and accurately predicts gamma amplitude across 86 images. Gamma responses were large for a small subset of stimuli, differing dramatically from fMRI and ECoG broadband (non-oscillatory) responses. We suggest that gamma oscillations in visual cortex serve as a biomarker of gain control rather than being a fundamental mechanism for communicating visual information.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2019">2019</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/relationship_between_cardiac_cycle_and_the_timing_of_actions_during_action_execution_and_observation_57446137/">
          <h4 class="font-weight-bold">Relationship between cardiac cycle and the timing of actions during action execution and observation, bioRxiv, 2019-03-22</h4>
          <p>AbstractPrevious research suggests that there may be a relationship between the timing of motor events and phases of the cardiac cycle. However, this relationship has thus far only been researched using simple isolated movements such as key-presses in reaction-time tasks and only in a single subject acting alone. Here, we investigated how the cardiac cycle relates to ongoing self-paced movements in both action execution and observation using a novel dyadic paradigm. We recorded electrocardiography (ECG) in 26 subjects who formed 13 dyads containing an action executioner and observer as they performed a self-paced sequence of movements. We demonstrated that heartbeats are timed to movements during both action execution and observation. Specifically, movements were more likely to culminate between heartbeats than simultaneously with the heartbeat. The same pattern was observed for action observation, with the observer’s heartbeats occurring off-phase with movement culmination. These findings demonstrate that there is synchronicity between an action executioner’s cardiac cycle and the timing of their movements, and that the same relationship is mirrored in an observer. This suggests that interpersonal synchronicity may be caused by the mirroring of a phasic relationship between movement and the heart.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2019">2019</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/a_critique_of_pure_learning_what_artificial_neural_networks_can_learn_from_animal_brains_57333723/">
          <h4 class="font-weight-bold">A Critique of Pure Learning What Artificial Neural Networks can Learn from Animal Brains, bioRxiv, 2019-03-20</h4>
          <p>ABSTRACTOver the last decade, artificial neural networks (ANNs), have undergone a revolution, catalyzed in large part by better tools for supervised learning. However, training such networks requires enormous data sets of labeled examples, whereas young animals (including humans) typically learn with few or no labeled examples. This stark contrast with biological learning has led many in the ANN community posit that instead of supervised paradigms, animals must rely instead primarily on unsupervised learning, leading the search for better unsupervised algorithms. Here we argue that much of an animal’s behavioral repertoire is not the result of clever learning algorithms—supervised or unsupervised—but arises instead from behavior programs already present at birth. These programs arise through evolution, are encoded in the genome, and emerge as a consequence of wiring up the brain. Specifically, animals are born with highly structured brain connectivity, which enables them learn very rapidly. Recognizing the importance of the highly structured connectivity suggests a path toward building ANNs capable of rapid learning.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/200-500-users">200-500-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2019">2019</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/variations_in_structural_mri_quality_impact_measures_of_brain_anatomy_relations_with_age_and_other_sociodemographic_variables_57336712/">
          <h4 class="font-weight-bold">Variations in Structural MRI Quality Impact Measures of Brain Anatomy Relations with Age and Other Sociodemographic Variables, bioRxiv, 2019-03-20</h4>
          <p>AbstractIn-scanner head movements can introduce artifacts to MRI images and increase errors in brain-behavior studies. The magnitude of in-scanner head movements varies widely across developmental and clinical samples, making it increasingly difficult to parse out “true signal” from motion related noise. Yet, the quantification of structural imaging quality is typically limited to subjective visual assessments andor proxy measures of motion. It is, however, unknown how direct measures of image quality relate to developmental and behavioral variables, as well as measures of brain morphometrics. To begin to answer this question, we leverage a multi-site dataset of structural MRI images, which includes a range of children and adolescents with varying degrees of psychopathology. We first find that a composite of structural image quality relates to important developmental and behavioral variables (e.g., IQ; clinical diagnoses). Additionally, we demonstrate that even among T1-weighted images which pass visual inspection, variations in image quality impact volumetric derivations of regional gray matter. Image quality was associated with wide-spread variations in gray matter, including in portions of the frontal, parietal, and temporal lobes, as well as the cerebellum. Further, our image quality composite partially mediated the relationship between age and total gray matter volume, explaining 23% of this relationship. Collectively, the effects underscore the need for volumetric studies to model or mitigate the effect of image quality when investigating brain-behavior relations.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2019">2019</a>
          
        
      </div>
    </div>
  
</main>
<br>
<main>
  


<nav aria-label="page navigation">
    <ul class="pagination">
        
        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/" rel="first" class="page-link">« First</a></li>
        

        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/16/" rel="prev" class="page-link">‹ Prev</a></li>
        

        
             
            
            <li class="page-item disabled"><a class="page-link">...</a></li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/13/" class="page-link">13</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/14/" class="page-link">14</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/15/" class="page-link">15</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/16/" class="page-link">16</a></li>
            
        
             
            <li class="page-item active"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/17/" class="page-link">17</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/18/" class="page-link">18</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/19/" class="page-link">19</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/20/" class="page-link">20</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/21/" class="page-link">21</a></li>
            
        
             
            
            <li class="page-item disabled"><a class="page-link">...</a></li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        

        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/18/" rel="next" class="page-link">Next ›</a></li>
        

        
        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/53/" rel="last" class="page-link">Last »</a></li>
        
    </ul>
</nav>


</main>

&nbsp;
<hr />
<p style="text-align: center;">Created with the <a href="https://github.com/carjed/audiences">audiences framework </a> by <a href="https://github.com/carjed/">Jedidiah Carlson</a></p>
<p style="text-align: center;">Powered by <a href="https://gohugo.io/">Hugo </a></p>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<p style="text-align: center;">
    <a href="https://twitter.com/JedMSP?lang=en" class="fa fa-twitter"></a>
    <a href="https://github.com/carjed/" class="fa fa-github"></a>
</p>

&nbsp;

</div>
  
</body>
</html>
