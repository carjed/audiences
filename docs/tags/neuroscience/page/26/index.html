<!DOCTYPE html>
<html><head>
  
  <title>Neuroscience | audiences</title>
  
  <link rel="stylesheet" href='css/bootstrap.min.css'>
  <link rel="stylesheet" href='css/mondrian.css'>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.52" />
  

<style>

  #grid .list-item.page:hover {
    background: white;
  }
  main.single.page h1 {
    border-color: white;
  }

  #grid .list-item.reports:hover {
    background: gold;
  }
  main.single.reports h1 {
    border-color: gold;
  }

  #grid .list-item.summary:hover {
    background: limegreen;
  }
  main.single.summary h1 {
    border-color: limegreen;
  }

</style>
  









<script src="/js/bundle.min.04bd3499e23e665b761954011cfb58a5988ae72a56495d664077f360ae1c92545ea2a31eb009c0215fd62914601dd0a6fcc660a502754b40526292d8429fcdbc.js" integrity="sha512-BL00meI&#43;Zlt2GVQBHPtYpZiK5ypWSV1mQHfzYK4cklReoqMesAnAIV/WKRRgHdCm/MZgpQJ1S0BSYpLYQp/NvA=="></script>

  <style></style>
  
  
</head>
<body>
  <div class="container-fluid h-100 d-flex flex-column">
<header class="row flex-shrink-0 justify-content-center justify-content-md-start">
  <ul class="nav px-2">
    <li class="p-2">
      <a class="text-muted text-decoration-none" href="/">audiences</a>
    </li>
    
      <li class="p-2">
        <a class="text-light" href="/reports" title="">reports</a>
      </li>
    
      <li class="p-2">
        <a class="text-light" href="/search" title="">search</a>
      </li>
    
  </nav>
</header>

<main id="grid" class="row list flex-wrap h-99 text-center">
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="/reports/a_suite_of_transgenic_driver_and_reporter_mouse_lines_with_enhanced_brain_cell_type_targeting_and_functionality_29448543/">
          <h4 class="font-weight-bold">A suite of transgenic driver and reporter mouse lines with enhanced brain cell type targeting and functionality, bioRxiv, 2017-11-26</h4>
          <p>SUMMARYModern genetic approaches are powerful in providing access to diverse types of neurons within the mammalian brain and greatly facilitating the study of their function. We here report a large set of driver and reporter transgenic mouse lines, including 23 new driver lines targeting a variety of cortical and subcortical cell populations and 26 new reporter lines expressing an array of molecular tools. In particular, we describe the TIGRE2.0 transgenic platform and introduce Cre-dependent reporter lines that enable optical physiology, optogenetics, and sparse labeling of genetically-defined cell populations. TIGRE2.0 reporters broke the barrier in transgene expression level of single-copy targeted-insertion transgenesis in a wide range of neuronal types, along with additional advantage of a simplified breeding strategy compared to our first-generation TIGRE lines. These novel transgenic lines greatly expand the repertoire of high-precision genetic tools available to effectively identify, monitor, and manipulate distinct cell types in the mouse brain.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/200-500-users">200-500-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2017">2017</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="/reports/human_vmpfc_encodes_early_signatures_of_confidence_in_perceptual_decisions_29448546/">
          <h4 class="font-weight-bold">Human VMPFC encodes early signatures of confidence in perceptual decisions, bioRxiv, 2017-11-26</h4>
          <p>AbstractChoice confidence, an individual’s internal estimate of judgment accuracy, plays a critical role in adaptive behaviour. Despite its importance, the early (decisional) stages of confidence processing remain underexplored. Here, we recorded simultaneous EEGfMRI while participants performed a direction discrimination task and rated their confidence on each trial. Using multivariate single-trial discriminant analysis of the EEG, we identified a stimulus- and accuracy-independent component encoding confidence, appearing prior to subjects’ choice and explicit confidence report. The trial-to-trial variability in this EEG-derived confidence signal was uniquely associated with fMRI responses in the ventromedial prefrontal cortex (VMPFC), a region not typically associated with confidence for perceptual decisions. Furthermore, we showed that the VMPFC was functionally coupled with regions of the prefrontal cortex that support neural representations of confidence during explicit metacognitive report. Our results suggest that the VMPFC encodes an early confidence readout, preceding and potentially informing metacognitive evaluation and learning, by acting as an implicit valuereward signal.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2017">2017</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="/reports/sensory_cortex_is_optimised_for_prediction_of_future_input_29402530/">
          <h4 class="font-weight-bold">Sensory cortex is optimised for prediction of future input, bioRxiv, 2017-11-25</h4>
          <p>Neurons in sensory cortex are tuned to diverse features in natural scenes. But what determines which features neurons become selective to? Here we explore the idea that neuronal selectivity is optimised to represent features in the recent past of sensory input that best predict immediate future inputs. We tested this hypothesis using simple feedforward neural networks, which were trained to predict the next few video or audio frames in clips of natural scenes. The networks developed receptive fields that closely matched those of real cortical neurons, including the oriented spatial tuning of primary visual cortex, the frequency selectivity of primary auditory cortex and, most notably, in their temporal tuning properties. Furthermore, the better a network predicted future inputs the more closely its receptive fields tended to resemble those in the brain. This suggests that sensory processing is optimised to extract those features with the most capacity to predict future input.Impact statementPrediction of future input explains diverse neural tuning properties in sensory cortex.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2017">2017</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="/reports/eye_movement-related_confounds_in_neural_decoding_of_visual_working_memory_representations_29183431/">
          <h4 class="font-weight-bold">Eye movement-related confounds in neural decoding of visual working memory representations, bioRxiv, 2017-11-21</h4>
          <p>AbstractThe study of visual working memory (VWM) has recently seen revitalization with the emergence of new insights and theories regarding its neural underpinnings. One crucial ingredient responsible for this progress is the rise of neural decoding techniques. These techniques promise to uncover the representational contents of neural signals, as well as the underlying code and the dynamic profile thereof. Here, we aimed to contribute to the field by subjecting human volunteers to a combined VWMimagery task, while recording and decoding their neural signals as measured by MEG. At first sight, the results seem to provide evidence for a persistent, stable representation of the memorandum throughout the delay period. However, control analyses revealed that these findings can be explained by subtle, VWM-specific eye movements. As a potential remedy, we demonstrate the use of a functional localizer, which was specifically designed to target bottom-up sensory signals and as such avoids eye movements, to train the neural decoders. This analysis revealed a sustained representation for approximately 1 second, but no longer throughout the entire delay period. We conclude by arguing for more awareness of the potentially pervasive and ubiquitous effects of eye movement-related confounds.Significance statementVisual working memory is an important aspect of higher cognition and has been subject of much investigation within the field of cognitive neuroscience. Over recent years, these studies have increasingly relied on the use of neural decoding techniques. Here, we show that neural decoding may be susceptible to confounds induced by stimulus-specific eye movements. Such eye movements during working memory have been reported before, and may in fact be a common phenomenon. Given the widespread use of neural decoding and the potentially contaminating effects of eye movements, we therefore believe that our results are of significant relevance for the field.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2017">2017</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="/reports/the_generation_and_propagation_of_the_human_alpha_rhythm_29116146/">
          <h4 class="font-weight-bold">The Generation and Propagation of the Human Alpha Rhythm, bioRxiv, 2017-11-19</h4>
          <p>AbstractThe alpha rhythm is the longest studied brain oscillation and has been theorized to play a key role in cognition. Still, its physiology is poorly understood. In this study, we used micro and macro electrodes in surgical epilepsy patients to measure the intracortical and thalamic generators of the alpha rhythm during quiet wakefulness. We first found that alpha in posterior cortex propagates from higher-order anterosuperior areas towards the occipital pole, consistent with alpha effecting top-down processing. This cortical alpha leads pulvinar alpha, complicating prevailing theories of a thalamic pacemaker. Finally, alpha is dominated by currents and firing in supragranular cortical layers. Together, these results suggest that the alpharhythm likely reflects short-range supragranular feedback which propagates from higher to lower-order cortex and cortex to thalamus. These physiological insights suggest how alpha could mediate feedback throughout the thalamocortical system.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2017">2017</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="/reports/resting-state_functional_brain_connectivity_best_predicts_the_personality_dimension_of_openness_to_experience_28554982/">
          <h4 class="font-weight-bold">Resting-state functional brain connectivity best predicts the personality dimension of openness to experience, bioRxiv, 2017-11-14</h4>
          <p>AbstractPersonality neuroscience aims to find associations between brain measures and personality traits. Findings to date have been severely limited by a number of factors, including small sample size and omission of out-of-sample prediction. We capitalized on the recent availability of a large database, together with the emergence of specific criteria for best practices in neuroimaging studies of individual differences. We analyzed resting-state functional magnetic resonance imaging data from 884 young healthy adults in the Human Connectome Project (HCP) database. We attempted to predict personality traits from the “Big Five”, as assessed with the NEO-FFI test, using individual functional connectivity matrices. After regressing out potential confounds (such as age, sex, handedness and fluid intelligence), we used a cross-validated framework, together with test-retest replication (across two sessions of resting-state fMRI for each subject), to quantify how well the neuroimaging data could predict each of the five personality factors. We tested three different (published) denoising strategies for the fMRI data, two inter-subject alignment and brain parcellation schemes, and three different linear models for prediction. As measurement noise is known to moderate statistical relationships, we performed final prediction analyses using average connectivity across both imaging sessions (1 h of data), with the analysis pipeline that yielded the highest predictability overall. Across all results (testretest; 3 denoising strategies; 2 alignment schemes; 3 models), Openness to experience emerged as the only reliably predicted personality factor. Using the full hour of resting-state data and the best pipeline, we could predict Openness to experience (NEOFAC_O r=0.24, R2=0.024) almost as well as we could predict the score on a 24-item intelligence test (PMAT24_A_CR r=0.26, R2=0.044). Other factors (Extraversion, Neuroticism, Agreeableness and Conscientiousness) yielded weaker predictions across results that were not statistically significant under permutation testing. We also derived two superordinate personality factors (“α” and “β”) from a principal components analysis of the NEO-FFI factor scores, thereby reducing noise and enhancing the precision of these measures of personality. We could account for 5% of the variance in the β superordinate factor (r=0.27, R2=0.050), which loads highly on Openness to experience. We conclude with a discussion of the potential for predicting personality from neuroimaging data and make specific recommendations for the field.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="/tags/2017">2017</a>
          
        
      </div>
    </div>
  
</main>
<br>
<main>
  


<nav aria-label="page navigation">
    <ul class="pagination">
        
        
        <li class="page-item"><a href="/tags/neuroscience/" rel="first" class="page-link">« First</a></li>
        

        
        <li class="page-item"><a href="/tags/neuroscience/page/25/" rel="prev" class="page-link">‹ Prev</a></li>
        

        
             
            
            <li class="page-item disabled"><a class="page-link">...</a></li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/22/" class="page-link">22</a></li>
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/23/" class="page-link">23</a></li>
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/24/" class="page-link">24</a></li>
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/25/" class="page-link">25</a></li>
            
        
             
            <li class="page-item active"><a href="/tags/neuroscience/page/26/" class="page-link">26</a></li>
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/27/" class="page-link">27</a></li>
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/28/" class="page-link">28</a></li>
            
        
            
             
            <li class="page-item"><a href="/tags/neuroscience/page/29/" class="page-link">29</a></li>
            
        

        
        <li class="page-item"><a href="/tags/neuroscience/page/27/" rel="next" class="page-link">Next ›</a></li>
        

        
        
        <li class="page-item"><a href="/tags/neuroscience/page/29/" rel="last" class="page-link">Last »</a></li>
        
    </ul>
</nav>


</main>

&nbsp;
<hr />
<p style="text-align: center;">Created with the <a href="https://github.com/carjed/audiences">audiences framework </a> by <a href="https://github.com/carjed/">Jedidiah Carlson</a></p>
<p style="text-align: center;">Powered by <a href="https://gohugo.io/">Hugo </a></p>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<p style="text-align: center;">
    <a href="https://twitter.com/JedMSP?lang=en" class="fa fa-twitter"></a>
    <a href="https://www.linkedin.com/in/jedidiah/" class="fa fa-linkedin"></a>
    <a href="https://github.com/carjed/" class="fa fa-github"></a>
</p>

&nbsp;

</div>
  
</body>
</html>
