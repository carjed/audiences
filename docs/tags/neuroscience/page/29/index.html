<!DOCTYPE html>
<html><head>
  
  <title>Neuroscience | audiences</title>
  
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/bootstrap.min.css'>
  <link rel="stylesheet" href='https://carjed.github.io/audiences/css/mondrian.css'>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.52" />
  

<style>

  #grid .list-item.page:hover {
    background: white;
  }
  main.single.page h1 {
    border-color: white;
  }

  #grid .list-item.reports:hover {
    background: gold;
  }
  main.single.reports h1 {
    border-color: gold;
  }

  #grid .list-item.summary:hover {
    background: limegreen;
  }
  main.single.summary h1 {
    border-color: limegreen;
  }

</style>
  









<script src="https://carjed.github.io/audiences/js/bundle.min.f25ff27688046eb318bdc22977150cde493b69297eb61c33d467745adf840d358a2427ed01d7dc1e0bd54c4d5831f1ed5e9bc1e1f7187533a24e36d63659607f.js" integrity="sha512-8l/ydogEbrMYvcIpdxUM3kk7aSl&#43;thwz1Gd0Wt&#43;EDTWKJCftAdfcHgvVTE1YMfHtXpvB4fcYdTOiTjbWNllgfw=="></script>

  <style></style>
  
  
</head>
<body>
  <div class="container-fluid h-100 d-flex flex-column">
<header class="row flex-shrink-0 justify-content-center justify-content-md-start">
  <ul class="nav px-2">
    <li class="p-2">
      <a class="text-muted text-decoration-none" href="https://carjed.github.io/audiences/">audiences</a>
    </li>
    
      <li class="p-2">
        <a class="text-light" href="https://carjed.github.io/audiences/reports" title="">reports</a>
      </li>
    
      <li class="p-2">
        <a class="text-light" href="https://carjed.github.io/audiences/search" title="">search</a>
      </li>
    
  </nav>
</header>

<main id="grid" class="row list flex-wrap h-99 text-center">
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/fast_two-photon_volumetric_imaging_of_an_improved_voltage_indicator_reveals_electrical_activity_in_deeply_located_neurons_in_the_awake_brain_49859230/">
          <h4 class="font-weight-bold">Fast two-photon volumetric imaging of an improved voltage indicator reveals electrical activity in deeply located neurons in the awake brain, bioRxiv, 2018-10-17</h4>
          <p>ABSTRACTImaging of transmembrane voltage deep in brain tissue with cellular resolution has the potential to reveal information processing by neuronal circuits in living animals with minimal perturbation. Multi-photon voltage imaging in vivo, however, is currently limited by speed and sensitivity of both indicators and imaging methods. Here, we report the engineering of an improved genetically encoded voltage indicator, ASAP3, which exhibits up to 51% fluorescence responses in the physiological voltage range, sub-millisecond activation kinetics, and full responsivity under two-photon illumination. We also introduce an ultrafast local volume excitation (ULOVE) two-photon scanning method to sample ASAP3 signals in awake mice at kilohertz rates with increased stability and sensitivity. ASAP3 and ULOVE allowed continuous single-trial tracking of spikes and subthreshold events for minutes in deep locations, with subcellular resolution, and with repeated sampling over multiple days. By imaging voltage in visual cortex neurons, we found evidence for cell type-dependent subthreshold modulation by locomotion. Thus, ASAP3 and ULOVE enable continuous high-speed high-resolution imaging of electrical activity in deeply located genetically defined neurons during awake behavior.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/how_face_perception_unfolds_over_time_49789229/">
          <h4 class="font-weight-bold">How face perception unfolds over time, bioRxiv, 2018-10-17</h4>
          <p>Within a fraction of a second of viewing a face, we have already determined its gender, age and identity. A full understanding of this remarkable feat will require a characterization of the computational steps it entails, along with the representations extracted at each. To this end, we used magnetoencephalography to measure the time course of neural responses to faces, thereby addressing two fundamental questions about how face processing unfolds over time. First, using representational similarity analysis, we found that facial gender and age information emerged before identity information, suggesting a coarse-to-fine processing of face dimensions. Second, identity and gender representations of familiar faces were enhanced very early on, indicating that the previously-reported behavioral benefit for familiar faces results from tuning of early feed-forward processing mechanisms. These findings start to reveal the time course of face perception in humans, and provide powerful new constraints on computational theories of face perception.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/200-500-users">200-500-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/brain-wide_cellular_resolution_imaging_of_cre_transgenic_zebrafish_lines_for_functional_circuit-mapping_49724290/">
          <h4 class="font-weight-bold">Brain-wide cellular resolution imaging of Cre transgenic zebrafish lines for functional circuit-mapping, bioRxiv, 2018-10-15</h4>
          <p>AbstractDecoding the functional connectivity of the nervous system is facilitated by transgenic methods that express a genetically encoded reporter or effector in specific neurons; however, most transgenic lines show broad spatiotemporal and cell-type expression. Increased specificity can be achieved using intersectional genetic methods which restrict reporter expression to cells that co-express multiple drivers, such as Gal4 and Cre. To facilitate intersectional targeting in zebrafish, we have generated more than 50 new Cre lines, and co-registered brain expression images with the Zebrafish Brain Browser, a cellular resolution atlas of 264 transgenic lines. Lines labeling neurons of interest can be identified using a web-browser to perform a 3D spatial search (&lt;jatsext-link xmlnsxlink=httpwww.w3.org1999xlink ext-link-type=uri xlinkhref=httpzbbrowser.com&gt;zbbrowser.com&lt;jatsext-link&gt;). This resource facilitates the design of intersectional genetic experiments and will advance a wide range of precision circuit-mapping studies.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/a_framework_for_intelligence_and_cortical_function_based_on_grid_cells_in_the_neocortex_49622119/">
          <h4 class="font-weight-bold">A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex, bioRxiv, 2018-10-13</h4>
          <p>AbstractHow the neocortex works is a mystery. In this paper we propose a novel framework for understanding its function. Grid cells are neurons in the entorhinal cortex that represent the location of an animal in its environment. Recent evidence suggests that grid cell-like neurons may also be present in the neocortex. We propose that grid cells exist throughout the neocortex, in every region and in every cortical column. They define a location-based framework for how the neocortex functions. Whereas grid cells in the entorhinal cortex represent the location of one thing, the body relative to its environment, we propose that cortical grid cells simultaneously represent the location of many things. Cortical columns in somatosensory cortex track the location of tactile features relative to the object being touched and cortical columns in visual cortex track the location of visual features relative to the object being viewed. We propose that mechanisms in the entorhinal cortex and hippocampus that evolved for learning the structure of environments are now used by the neocortex to learn the structure of objects. Having a representation of location in each cortical column suggests mechanisms for how the neocortex represents object compositionality and object behaviors. It leads to the hypothesis that every part of the neocortex learns complete models of objects and that there are many models of each object distributed throughout the neocortex. The similarity of circuitry observed in all cortical regions is strong evidence that even high-level cognitive tasks are learned and represented in a location-based framework.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/100-200-users">100-200-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/measuring_the_average_power_of_neural_oscillations_49625253/">
          <h4 class="font-weight-bold">Measuring the average power of neural oscillations, bioRxiv, 2018-10-13</h4>
          <p>AbstractBackgroundNeural oscillations are often quantified as average power relative to a cognitive, perceptual, andor behavioral task. This is commonly done using Fourier-based techniques, such as Welch’s method for estimating the power spectral density, andor by estimating narrowband oscillatory power across trials, conditions, andor groups. The core assumption underlying these approaches is that the mean is an appropriate measure of central tendency. Despite the importance of this assumption, it has not been rigorously tested.New methodWe introduce extensions of common approaches that are better suited for the physiological reality of how neural oscillations often manifest as nonstationary, high-power bursts, rather than sustained rhythms. Log-transforming, or taking the median power, significantly reduces erroneously inflated power estimates.ResultsAnalyzing 101 participants’ worth of human electrophysiology, totaling 3,560 channels and over 40 hours data, we show that, in all cases examined, spectral power is not Gaussian distributed. This is true even when oscillations are prominent and sustained, such as visual cortical alpha. Power across time, at every frequency, is characterized by a substantial long tail, which implies that estimates of average power are skewed toward large, infrequent high-power oscillatory bursts.Comparison with existing methodsIn a simulated event-related experiment we show how introducing just a few high-power oscillatory bursts, as seen in real data, can, perhaps erroneously, cause significant differences between conditions using traditional methods. These erroneous effects are substantially reduced with our new methods.ConclusionsThese results call into question the validity of common statistical practices in neural oscillation research.Highlights&lt;jatslist list-type=bullet&gt;&lt;jatslist-item&gt;Analyses of oscillatory power often assume power is normally distributed.&lt;jatslist-item&gt;&lt;jatslist-item&gt;Analyzing &amp;gt;40 hours of human MEEG and ECoG, we show that in all cases it is not.&lt;jatslist-item&gt;&lt;jatslist-item&gt;This effect is demonstrated in simple simulation of an event-related task.&lt;jatslist-item&gt;&lt;jatslist-item&gt;Overinflated power estimates are reduced via log-transformation or median power.&lt;jatslist-item&gt;</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2018">2018</a>
          
        
      </div>
    </div>
  
    <div class="list-item d-flex lead justify-content-center align-items-center reports">
      <div>
        <a class="text-decoration-none" href="https://carjed.github.io/audiences/reports/the_flexiscope_a_low_cost_flexible_convertible_and_modular_microscope_with_automated_scanning_and_micromanipulation_49607835/">
          <h4 class="font-weight-bold">The Flexiscope a Low Cost, Flexible, Convertible, and Modular Microscope with Automated Scanning and Micromanipulation, bioRxiv, 2018-10-13</h4>
          <p>AbstractWith technologies rapidly evolving, many research institutions are now opting to invest in costly, high-quality, specialised microscopes which are shared by many researchers. As a consequence, the user does not have the ability to adapt a microscope to their specific needs and limitations in experimental design are introduced. A flexible work-horse microscopy system is a valuable tool in any laboratory to meet the diverse needs of a research team and promote innovation in experimental design. We have developed the Flexiscope; a multi-functional, adaptable, efficient and high performance microscopyelectrophysiology system for everyday applications in a neurobiology laboratory. The core optical components are relatively constant in the three configurations described here; an upright configuration, an inverted configuration and an uprightelectrophysiology configuration. We have provided a comprehensive description of the Flexiscope. We show that this method is capable of oblique infrared illumination imaging, multi-channel fluorescent imaging, and automated 3D scanning of larger specimens. Image quality is conserved across the three configurations of the microscope, and conversion between configurations is possible quickly and easily, while the motion control system can be repurposed to allow sub-micron computer-controlled micromanipulation. The Flexiscope provides similar performance and usability to commercially available systems. However, as it can be easily reconfigured for multiple roles, it can remove the need to purchase multiple microscopes, giving significant cost savings. The modular re-configurable nature allows the user to customise the system to their specific needs and adaptupgrade the system as challenges arise.</p>
        </a>
        
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/biorxiv">biorxiv</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/neuroscience">neuroscience</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/0-100-users">0-100-users</a>
          
            <a class="text-body text-decoration-none border-bottom border-dark" href="https://carjed.github.io/audiences/tags/2018">2018</a>
          
        
      </div>
    </div>
  
</main>
<br>
<main>
  


<nav aria-label="page navigation">
    <ul class="pagination">
        
        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/" rel="first" class="page-link">« First</a></li>
        

        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/28/" rel="prev" class="page-link">‹ Prev</a></li>
        

        
             
            
            <li class="page-item disabled"><a class="page-link">...</a></li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/25/" class="page-link">25</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/26/" class="page-link">26</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/27/" class="page-link">27</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/28/" class="page-link">28</a></li>
            
        
             
            <li class="page-item active"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/29/" class="page-link">29</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/30/" class="page-link">30</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/31/" class="page-link">31</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/32/" class="page-link">32</a></li>
            
        
            
             
            <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/33/" class="page-link">33</a></li>
            
        
             
            
            <li class="page-item disabled"><a class="page-link">...</a></li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        

        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/30/" rel="next" class="page-link">Next ›</a></li>
        

        
        
        <li class="page-item"><a href="https://carjed.github.io/audiences/tags/neuroscience/page/53/" rel="last" class="page-link">Last »</a></li>
        
    </ul>
</nav>


</main>

&nbsp;
<hr />
<p style="text-align: center;">Created with the <a href="https://github.com/carjed/audiences">audiences framework </a> by <a href="https://github.com/carjed/">Jedidiah Carlson</a></p>
<p style="text-align: center;">Powered by <a href="https://gohugo.io/">Hugo </a></p>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


<p style="text-align: center;">
    <a href="https://twitter.com/JedMSP?lang=en" class="fa fa-twitter"></a>
    <a href="https://github.com/carjed/" class="fa fa-github"></a>
</p>

&nbsp;

</div>
  
</body>
</html>
